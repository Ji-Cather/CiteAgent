[
    
    {
        "model_type": "openai_chat",
        "config_name": "gpt-3.5-turbo-0125",
        "model_name": "gpt-3.5-turbo-0125",
        "api_key": "sk-.*",
        "generate_args": {
            "max_tokens": 2000,
            "temperature": 0.8
        },
        "client_args":{
            "base_url":"${base_url}"
        }
    },
    {
        "model_type": "openai_chat",
        "config_name": "gpt-4o-mini",
        "model_name": "gpt-4o-mini",
        "api_key": "sk-.*",
        "generate_args": {
            "max_tokens": 2000,
            "temperature": 0.8
        },
        "client_args":{
            "base_url":"${base_url}"
        }
    },
    {
        "config_name": "llama3-70b",
        "model_type": "openai_chat",
        "model_name": "llama3-70b-8192",
        "api_key": "sk-.*",
        "client_args": {
            "base_url":"${base_url}"
        },
        "generate_args": {
            "temperature": 0.8,
            "max_tokens": 2000
        }
    },
    {
        "config_name": "llama8b",
        "model_type": "openai_chat",
        "model_name": "llama3-8B",
        "api_key": "sk-.*",
        "client_args": {
            "base_url":""
        },
        "generate_args": {
            "temperature": 0.8,
            "max_tokens": 2000
        }
    }
]